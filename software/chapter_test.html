

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Testing &mdash; Software Engineering for Machine Learning  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/theme_overrides.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Web Services" href="chapter_ws.html" />
    <link rel="prev" title="Code Review" href="chapter_cr.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Software Engineering for Machine Learning
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../frontmatter/preface.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter_python.html">Introduction to Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter_vc.html">Version Control</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter_cr.html">Code Review</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#structure-of-tests">Structure of Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="#use-assert-correctly">Use Assert Correctly</a></li>
<li class="toctree-l2"><a class="reference internal" href="#exception">Exception</a></li>
<li class="toctree-l2"><a class="reference internal" href="#pytest">Pytest</a></li>
<li class="toctree-l2"><a class="reference internal" href="#test-integer-partition">Test Integer Partition</a></li>
<li class="toctree-l2"><a class="reference internal" href="#test-coverage">Test Coverage</a></li>
<li class="toctree-l2"><a class="reference internal" href="#continous-integration">Continous Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="#limitations-of-testing">Limitations of Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#halting-problems-unsolvable-problems">Halting Problems: Unsolvable Problems</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="chapter_ws.html">Web Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter_ci.html">Continuous Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter_graphics.html">Graphics</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter_reproducibility.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../unsupervised/chapter_ml.html">Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../unsupervised/chapter_kmeans.html">K-Means Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../unsupervised/chapter_hierarchical.html">Hierarchical Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../unsupervised/chapter_pca.html">Principal Component Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../unsupervised/chapter_practical.html">Practical Considerations of Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../unsupervised/chapter_floating_point.html">Floating Point and Finite Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised/chapter_supervised.html">Supervised Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised/chapter_gradient.html">Gradient Descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised/chapter_svm.html">Support Vector Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised/chapter_neural_networks.html">Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../misc/chapter_building_the_book.html">Building the Book using Sphinx, GitHub Pages, and Travis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../misc/chapter_sphinx_demo.html">Sphinx Demonstration</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Software Engineering for Machine Learning</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Testing</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/software/chapter_test.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="testing">
<h1>Testing<a class="headerlink" href="#testing" title="Permalink to this headline">¶</a></h1>
<p>Testing is an essential part for creating high-quality software.  Many
software developers understand the importance of testing but they do
not really understand how to write tests and they do not understand
the limitations of testing. This chaptper provides deeper insight
about testing.</p>
<div class="section" id="structure-of-tests">
<h2>Structure of Tests<a class="headerlink" href="#structure-of-tests" title="Permalink to this headline">¶</a></h2>
<p>Many books talk about the importance of testing and how to write tests.
However, few books talk about how to structure tests. Before writing any
test, you need to answer an important question: do you want the testing
code to be sent to the users (or customers)? In most cases, the answer
is no. The program used to generate the product sent to customers is
often called the “production code”. You do not want to include test code
inside production code for many reasons. First, including testing code
may make your product bigger (in terms of storage) and slower (in terms
of execution time). Worse, testing often needs specific inputs and the
expected outputs for these test cases. Will you also give these inputs
and outputs to your customers? If you do not, why do you include testing
code in the product?</p>
<p>Mixing production code and testing code is a common mistake for
beginning software developers. Worse, many of them have a lot of
“debugging messages” as they test code. When the program is ready for
production and release, what will they do with these debugging messages?
In almost all cases, your customers do not understand the debugging
messages and you have to remove the code printing these messages. Here
is the problem. When you remove the code printing these messages, the
risk is too high for one of two things to happen. First, you do not
remove all the code printing the debugging messages. Your customers are
annoyed by the mysterious debugging messages. Your competitors know more
than what you to reveal about your proudct. The second scenario is
worse. You accidentally remove more code than you intend and you
actually add bugs to your program. Your program no longer works and your
customers are very angry at your product.</p>
<p>The correct way of creating tests is to separate testing code from the
production code in different files (probably in different directories).
The production code does what it needs to do as the product. The testing
code tests the production code. When your product is ready, exclude the
testing code, the inputs, and the expected outputs before releasing your
product. Figure <a class="reference external" href="#fig:teststructure01">[fig:teststructure01]</a>
illustrates this concept.</p>
<div class="figure align-default" id="id1">
<img alt="../_images/teststructure01.png" src="../_images/teststructure01.png" />
<p class="caption"><span class="caption-number">Figure 33 </span><span class="caption-text">Production code and test code should be completely separated.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="use-assert-correctly">
<h2>Use Assert Correctly<a class="headerlink" href="#use-assert-correctly" title="Permalink to this headline">¶</a></h2>
<p>Another common mistake among beginning software developers is to use
assert incorrectly. This is what they often do.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># This is production code</span>
<span class="o">....</span>
<span class="k">assert</span><span class="p">(</span><span class="n">condition</span> <span class="n">that</span> <span class="n">should</span> <span class="n">be</span> <span class="n">true</span><span class="p">)</span>
<span class="o">....</span>
</pre></div>
</div>
<p>This is one example how assert may be used:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>There are three problems when you do this. First, if the condition is
not true, the program immediately stops. There is no second chance.
Imagine that your program is a text editor. When a user wants to save
the content to a file, your program does not want to erase an existing
file. You put assert there claiming that the file must not exist. If a
user accidentially uses a file whose name already exists, the program
stops and everything typed by the user is lost. You will definietely
have a user that will never buy any product from you. Some people argue
that “I put assert there because I know it must be true.” That argument
is self-contraditory. If you know that the condition must be true, you
will not put assert there. Would you write</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="p">(</span><span class="mi">1</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>You don’t.</p>
<p>If you are abosolutly certain the condition must be true, you do not
need to put assert there.</p>
<p>Some people say, “I will remove all assert before releasing the
product.” This can be done easily using the grep -v command. This,
however, brings the second problem. What would happen if some of the
assert statements actually do something useful? Consider the following
case:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>This assigns y’s value to x.</p>
<p>What you really want to do is probably to ensure that x and y are the
same:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>The earlier assert statement assigns y’s value to x. Hence, their
values are same and the intended assert is actually true. If you
remove the assert and no longer assign y’s value to x, the program may
not work any more. Human eyes are not good detecting the differences
between = and ==. This is a difficult bug to fix because keeping
assert means the program is correct. Removing assert means the program
is wrong.  These problems about misuse <code class="docutils literal notranslate"><span class="pre">assert</span></code> were observed in the
authors’ classes.  They actually happened multiple times.</p>
<p>The third problem is, perhaps, somewhat philosophical. It is the
attitude of creating good software. Software is deployed in many
safety-critical systems. Mistakes in these systems may cause signficant
amounts of financial losses, body injuries, or even deaths. Allowing a
program to sudden stop is simply an unacceptable way of thinking. Using
assert is an irresponsible way of writing production code. It expresses
the attutide “Something is not expected. My program commits suicide and
the rest is not my problem any more.” A more responsbile way of writing
good software is to handle the problem and do not stop the program.</p>
<p>If assert has these problems, does that mean assert should not be used
at all? You should not use assert in production code. You can use assert
in the testing code, as shown in
Figure <a class="reference external" href="#fig:teststructure02">[fig:teststructure02]</a>.</p>
<div class="figure align-default">
<img alt="../_images/teststructure02.png" src="../_images/teststructure02.png" />
</div>
<p>Use <code class="docutils literal notranslate"><span class="pre">assert</span></code> in the testing code. Do not put <code class="docutils literal notranslate"><span class="pre">assert</span></code> in  production code.</p>
<p>In this example, the testing code uses assert to check whether the
output from function 1 is correct. This is particularly important before
sending it to the input of function 2. This further emphasizes the
importance of separating production code from testing code.</p>
</div>
<div class="section" id="exception">
<h2>Exception<a class="headerlink" href="#exception" title="Permalink to this headline">¶</a></h2>
<p>To be added later</p>
</div>
<div class="section" id="pytest">
<h2>Pytest<a class="headerlink" href="#pytest" title="Permalink to this headline">¶</a></h2>
<p>Python has a tool for testing calle pytest. It automatically looks for
the files starting with test_ and ending with .py and executes the
functions whose names start with test_. The following is a simple
example.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/python3</span>
<span class="c1"># test_example1.py</span>

<span class="k">def</span> <span class="nf">returntrue</span><span class="p">():</span>
    <span class="k">return</span> <span class="kc">True</span>

<span class="k">def</span> <span class="nf">returnfalse</span><span class="p">():</span>
    <span class="k">return</span> <span class="kc">False</span>

<span class="k">def</span> <span class="nf">test_truefalse</span><span class="p">():</span>
    <span class="k">assert</span> <span class="n">returntrue</span><span class="p">()</span> <span class="o">==</span> <span class="kc">True</span>
    <span class="k">assert</span> <span class="n">returnfalse</span><span class="p">()</span> <span class="o">==</span> <span class="kc">False</span>
    
</pre></div>
</div>
<p>Running pytest gets the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ pytest
============ test session starts =============
platform linux -- Python 3.5.2, pytest-4.3.0, py-1.8.0, pluggy-0.9.0
rootdir: /..., inifile:
collected 1 item

test_example1.py .
</pre></div>
</div>
<p>Here, the rootdir is the directory where you run pytest. This output
means the tests have passed.</p>
<p>Change the program as follows: returntrue returns False and returnfalse
returns True:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/python3</span>
<span class="c1"># test_example2.py</span>

<span class="k">def</span> <span class="nf">returntrue</span><span class="p">():</span>
    <span class="k">return</span> <span class="kc">False</span>

<span class="k">def</span> <span class="nf">returnfalse</span><span class="p">():</span>
    <span class="k">return</span> <span class="kc">True</span>

<span class="k">def</span> <span class="nf">test_truefalse</span><span class="p">():</span>
    <span class="k">assert</span> <span class="n">returntrue</span><span class="p">()</span> <span class="o">==</span> <span class="kc">True</span>
    <span class="k">assert</span> <span class="n">returnfalse</span><span class="p">()</span> <span class="o">==</span> <span class="kc">False</span>
    
</pre></div>
</div>
<p>Running pytest gets this result, showing the test has failed.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">========================</span> <span class="n">FAILURES</span> <span class="o">========================</span>
<span class="n">____________________</span> <span class="n">test_truefalse</span> <span class="n">______________________</span>

    <span class="k">def</span> <span class="nf">test_truefalse</span><span class="p">():</span>
<span class="o">&gt;</span>       <span class="k">assert</span> <span class="n">returntrue</span><span class="p">()</span> <span class="o">==</span> <span class="kc">True</span>
<span class="n">E</span>       <span class="k">assert</span> <span class="kc">False</span> <span class="o">==</span> <span class="kc">True</span>
<span class="n">E</span>        <span class="o">+</span>  <span class="n">where</span> <span class="kc">False</span> <span class="o">=</span> <span class="n">returntrue</span><span class="p">()</span>

<span class="n">test_example2</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">11</span><span class="p">:</span> <span class="ne">AssertionError</span>
<span class="o">====================</span> <span class="mi">1</span> <span class="n">failed</span> <span class="ow">in</span> <span class="mf">0.04</span> <span class="n">seconds</span> <span class="o">====================</span>
</pre></div>
</div>
<p>When you create tests, it is important that you check whether the tests
may fail. Passing tests is not the purpose of testing. The purpose of
testing is to detect mistakes in production code and correct the code.
If a test can never fail, this test is useless.</p>
<p>Next, considers a slightly more complex program for testing two
functions: f1 and f2:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/python3</span>
<span class="c1"># test_example3.py</span>

<span class="k">def</span> <span class="nf">f1</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">f2</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">test_f1f2</span><span class="p">():</span>
    <span class="k">assert</span> <span class="n">f1</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span>
    <span class="k">assert</span> <span class="n">f1</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span> <span class="o">==</span> <span class="o">-</span><span class="mi">2</span>
    <span class="k">assert</span> <span class="n">f2</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span>
    
    
</pre></div>
</div>
<p>This is the output of pytest:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">========================</span> <span class="n">FAILURES</span> <span class="o">========================</span>
<span class="n">_______________________</span> <span class="n">test_f1f2</span> <span class="n">________________________</span>

    <span class="k">def</span> <span class="nf">test_f1f2</span><span class="p">():</span>
        <span class="k">assert</span> <span class="n">f1</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span>
        <span class="k">assert</span> <span class="n">f1</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span> <span class="o">==</span> <span class="o">-</span><span class="mi">2</span>
<span class="o">&gt;</span>       <span class="k">assert</span> <span class="n">f2</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span>
<span class="n">E</span>       <span class="k">assert</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">4</span>
<span class="n">E</span>        <span class="o">+</span>  <span class="n">where</span> <span class="mi">2</span> <span class="o">=</span> <span class="n">f2</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<span class="n">test_example3</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">13</span><span class="p">:</span> <span class="ne">AssertionError</span>
</pre></div>
</div>
<p>The result says that calling f1(3) and f1(-3) have passed the tests.
Calling f2(3) has failed because f2(3) return 2 but the test program
expects 4.</p>
<p>Earlier this chapter said testing code and production code should be
separated. The examples for pytest above violated this rule. The
following examples will follow the rule separating the testing code from
the tested code. Consider a file with two functions: f1 and f2:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># funcs.py</span>
<span class="k">def</span> <span class="nf">f1</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="nb">print</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">f2</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="nb">print</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span> <span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
    <span class="nb">print</span> <span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
    
</pre></div>
</div>
<p>This is the output when calling the functions interactively:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ python3
Python 3.5.2 (default, Nov 12 2018, 13:43:14)
[GCC 5.4.0 20160609] on linux
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt; import funcs
&gt;&gt;&gt; funcs.f1(3)
4
&gt;&gt;&gt; funcs.f2(5)
6
25
15
</pre></div>
</div>
<p>A test program calls funcs.f1(3) and funcs.f2(5).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/python3</span>
<span class="c1"># test_example4.py</span>
<span class="kn">import</span> <span class="nn">funcs</span>

<span class="k">def</span> <span class="nf">test_f1f2</span><span class="p">():</span>
    <span class="n">funcs</span><span class="o">.</span><span class="n">f1</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">funcs</span><span class="o">.</span><span class="n">f2</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    
    
    
</pre></div>
</div>
<p>This is the output when calling the functions interactively:</p>
<p>Running pytest, however, has no output. What is happening? Instead of
printing to a computer screen (also called the console), pytest,
captures the output. The reason is that pytest does not want to print
too many things. If too many things are printed to the screen, it is
likely that some important messages are ignored. Another reason is that
pytest often runs automatically when no human is watching (more details
about this later in the section on Continuous Integration). There are
two solutions: The first is to tell pytest to print to the screen by
adding -s after pytest. This defeats the purpose of pytest’s intention
not to print to the screen.</p>
<p>The second is a better and more general solution: it saves the captured
output to a file. It is actually quite straightforward:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/python3</span>
<span class="c1"># test_example5.py</span>

<span class="kn">import</span> <span class="nn">funcs</span>

<span class="k">def</span> <span class="nf">test_f1f2</span><span class="p">(</span><span class="n">capsys</span><span class="p">):</span>
    <span class="n">funcs</span><span class="o">.</span><span class="n">f1</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">funcs</span><span class="o">.</span><span class="n">f2</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">captureout</span><span class="p">,</span> <span class="n">captureerr</span> <span class="o">=</span> <span class="n">capsys</span><span class="o">.</span><span class="n">readouterr</span><span class="p">()</span>
    <span class="n">capturename</span> <span class="o">=</span> <span class="s1">&#39;capturedstdout&#39;</span>
    <span class="n">fhd</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">capturename</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
    <span class="n">fhd</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">captureout</span><span class="p">)</span>
    <span class="n">fhd</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    

    
    
</pre></div>
</div>
<p>The function test_f1f2() has an input for capturing the outputs. This
input will be provided automatically by pytest. To get the captured
output, it calls readouterr(). This function returns the captured output
to standard output (also called stdout) and the standard error (also
called stderr). Separating stdout from stderr gives more flexibility:
the former is the normal output and the latter is the error messages. By
default, both stdout and stderr are shown on a computer screen but it is
possible saving them to different files.</p>
<p>The testing program test_example5.py saves the standard output to a file
called capturedstdout. All outputs by the print statements in funcs are
saved in this file. The content of the file is (as expected)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">4</span>
<span class="mi">6</span>
<span class="mi">25</span>
<span class="mi">15</span>
</pre></div>
</div>
<p>When the outputs are saved to a file, testing can be done automatically
without human watching by following these steps:</p>
<ol class="arabic simple">
<li><p>write the expected output to a file</p></li>
<li><p>capture the output from pytest and save it to another file</p></li>
<li><p>compare the two files</p></li>
</ol>
<p>The following program shows these steps</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/python3</span>
<span class="c1"># test_example6.py</span>

<span class="kn">import</span> <span class="nn">filecmp</span>
<span class="kn">import</span> <span class="nn">funcs</span>

<span class="k">def</span> <span class="nf">test_f1f2</span><span class="p">(</span><span class="n">capsys</span><span class="p">):</span>
    <span class="n">funcs</span><span class="o">.</span><span class="n">f1</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">funcs</span><span class="o">.</span><span class="n">f2</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">captureout</span><span class="p">,</span> <span class="n">captureerr</span> <span class="o">=</span> <span class="n">capsys</span><span class="o">.</span><span class="n">readouterr</span><span class="p">()</span>
    <span class="n">capturename</span> <span class="o">=</span> <span class="s1">&#39;capturedstdout&#39;</span>
    <span class="n">fhd</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">capturename</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
    <span class="n">fhd</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">captureout</span><span class="p">)</span>
    <span class="n">fhd</span><span class="o">.</span><span class="n">close</span><span class="p">()</span> <span class="c1"># ensure that it has been saved</span>
    <span class="k">assert</span> <span class="n">filecmp</span><span class="o">.</span><span class="n">cmp</span><span class="p">(</span><span class="n">capturename</span><span class="p">,</span> <span class="s1">&#39;funcsexpected&#39;</span><span class="p">)</span>

    

    
    
</pre></div>
</div>
<p>The tests uses filecmp.cmp to compare the context of two files. As
explained, if a test cannot fail, it is useless. If funcs.f2(5) is
replaced by funcs.f2(4), pytest fails. This suggests that pytest is
actually testing funcs.f2.</p>
</div>
<div class="section" id="test-integer-partition">
<h2>Test Integer Partition<a class="headerlink" href="#test-integer-partition" title="Permalink to this headline">¶</a></h2>
<p>Only “toy” examples for pytest are shown so far. By capturing the
outputs, pytest can compare expected outputs with the actual outputs.
Thus, it becomes much easier testing many cases using a single test
program. The following program tests integer partition using three
different values: 3, 4, and 5. The expected outputs are stored in a
separate directory called expected and the files are called, not
surprisingly, 3, 4, and 5.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/python3</span>
<span class="c1"># test_intpart1.py</span>

<span class="kn">import</span> <span class="nn">intpart</span>
<span class="kn">import</span> <span class="nn">filecmp</span>

<span class="k">def</span> <span class="nf">run_test</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">expected</span><span class="p">,</span> <span class="n">capsys</span><span class="p">):</span>
    <span class="n">capturename</span> <span class="o">=</span> <span class="s1">&#39;capturedstdout&#39;</span>
    <span class="n">fhd</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">capturename</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">intpart</span><span class="o">.</span><span class="n">checkArgs</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="n">intpart</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="n">captured</span> <span class="o">=</span> <span class="n">capsys</span><span class="o">.</span><span class="n">readouterr</span><span class="p">()</span>
    <span class="n">fhd</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">captured</span><span class="o">.</span><span class="n">out</span><span class="p">)</span>
    <span class="n">fhd</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">assert</span> <span class="n">filecmp</span><span class="o">.</span><span class="n">cmp</span><span class="p">(</span><span class="n">capturename</span><span class="p">,</span> <span class="n">expected</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">test_intpart</span><span class="p">(</span><span class="n">capsys</span><span class="p">):</span>
    <span class="n">run_test</span><span class="p">(</span><span class="s1">&#39;3&#39;</span><span class="p">,</span> <span class="s1">&#39;expected/3&#39;</span><span class="p">,</span> <span class="n">capsys</span><span class="p">)</span>
    <span class="n">run_test</span><span class="p">(</span><span class="s1">&#39;4&#39;</span><span class="p">,</span> <span class="s1">&#39;expected/4&#39;</span><span class="p">,</span> <span class="n">capsys</span><span class="p">)</span>
    <span class="n">run_test</span><span class="p">(</span><span class="s1">&#39;5&#39;</span><span class="p">,</span> <span class="s1">&#39;expected/5&#39;</span><span class="p">,</span> <span class="n">capsys</span><span class="p">)</span>

    
</pre></div>
</div>
</div>
<div class="section" id="test-coverage">
<h2>Test Coverage<a class="headerlink" href="#test-coverage" title="Permalink to this headline">¶</a></h2>
<p>Test coverage means how much percentage of code that has been tested.
Getting test coverage is pretty easy: python has a program called
coverage. Simply adding coverage run before the program to be tested
(and the necessary arguments).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ coverage run intpart.py -e -o 5
-e and -o cannot be both set
$ coverage report
Name         Stmts   Miss  Cover
--------------------------------
intpart.py      50     26    48%
</pre></div>
</div>
<p>The first coverage run command executes the Python program intpart.py
with arguments -e -o 5. Since it is not possible partitioning any
integer using only even numbers and using only odd numbers at the same
time, the intpart.py program stops without partitioning the input value
5. The coverage is 48%.</p>
<p>To see which line has been tested, add annotate after coverage and the
file intpart.py,cover is created, as shown below</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>  #!/usr/bin/python3
  # intpart.py

&gt; import sys
&gt; import argparse

&gt; def printArray(arr, ind):
!   for i in range(0, ind - 1):
!     print (str(arr[i]) + &#39; + &#39;, end=&#39;&#39;)
!   print (str(arr[ind - 1]))

&gt; def partitionHelp(arr, ind, left, odd, even, order, notself):
!   if (left == 0):
      # if notself and ind is 1, then only one number is printed
      # this one number is itself
!     if ((not notself) or (ind &gt; 1)):
!       printArray(arr, ind)
!   &#39;&#39;&#39;
!   There are four conditions when this i is used
!   1. not odd and not even:
!   2. odd and i is odd
!   3. even and i is even
!   &#39;&#39;&#39;
!   for i in range(1, left + 1):
!     if (order and (ind != 0) and (arr[ind - 1] &gt; i)):
        # orders do not matter
        # the numbers must not be decreasing
!       continue
!     if ((not odd) and (not even)):
!       arr[ind] = i
!     elif (odd and (i % 2)):
!       arr[ind] = i
!     elif (even and ((i % 2) == 0)):
!       arr[ind] = i
!     else:
!       continue # do not use this value of i
!     partitionHelp(arr, ind + 1, left - i, odd, even, order, notself)

&gt; def partition(args):
    # print (args)
&gt;   odd = args.odd
&gt;   even = args.even
&gt;   order = args.order
&gt;   val = args.value
&gt;   notself = args.notself
&gt;   if (odd and even):
&gt;     sys.exit(&#39;-e and -o cannot be both set&#39;)
!   if (even and (val % 2)):
!     sys.exit(&#39;-e cannot partition an odd number&#39;)
!   print(&#39;== Partition &#39; + str(val) + &#39; ==&#39;)
!   if (odd):
!     print(&#39;== Using only odd numbers ==&#39;)
!   if (even):
!     print(&#39;== Using only even numbers ==&#39;)
!   arr = [0] * val
!   partitionHelp(arr, 0, val, odd, even, order, notself)

&gt; def checkArgs(args = None):
&gt;   parser = argparse.ArgumentParser(description=&#39;parse arguments&#39;)
&gt;   parser.add_argument(&#39;-o&#39;, &#39;--odd&#39;, action=&#39;store_true&#39;,
&gt;                       help = &#39;odd numbers only&#39;, default = False)
&gt;   parser.add_argument(&#39;-e&#39;, &#39;--even&#39;,action=&#39;store_true&#39;,
&gt;                       help = &#39;even numbers only&#39;, default = False)
&gt;   parser.add_argument(&#39;-r&#39;, &#39;--order&#39;,action=&#39;store_true&#39;,
&gt;                       help = &#39;orders do not matter&#39;, default = False)
&gt;   parser.add_argument(&#39;-s&#39;, &#39;--notself&#39;,action=&#39;store_true&#39;,
&gt;                       help = &#39;not to include itself&#39;, default = False)
&gt;   parser.add_argument(&#39;value&#39;, type = int,
&gt;                       help = &#39;number to parition&#39;)
&gt;   pargs = parser.parse_args(args)
&gt;   return pargs

&gt; if __name__== &quot;__main__&quot;:
&gt;   args = checkArgs(sys.argv[1:])
&gt;   partition(args)
</pre></div>
</div>
<p>If a line starts with &gt;, this line has been tested. If a line starts
with !, this line has not been tested.</p>
<p>Next, run intpart.py again without -e or -o. This time coverage report
says 80% code is covered and coverage annotate generates the following
file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>  #!/usr/bin/python3
  # intpart.py

&gt; import sys
&gt; import argparse

&gt; def printArray(arr, ind):
&gt;   for i in range(0, ind - 1):
&gt;     print (str(arr[i]) + &#39; + &#39;, end=&#39;&#39;)
&gt;   print (str(arr[ind - 1]))

&gt; def partitionHelp(arr, ind, left, odd, even, order, notself):
&gt;   if (left == 0):
      # if notself and ind is 1, then only one number is printed
      # this one number is itself
&gt;     if ((not notself) or (ind &gt; 1)):
&gt;       printArray(arr, ind)
&gt;   &#39;&#39;&#39;
&gt;   There are four conditions when this i is used
&gt;   1. not odd and not even:
&gt;   2. odd and i is odd
&gt;   3. even and i is even
&gt;   &#39;&#39;&#39;
&gt;   for i in range(1, left + 1):
&gt;     if (order and (ind != 0) and (arr[ind - 1] &gt; i)):
        # orders do not matter
        # the numbers must not be decreasing
!       continue
&gt;     if ((not odd) and (not even)):
&gt;       arr[ind] = i
!     elif (odd and (i % 2)):
!       arr[ind] = i
!     elif (even and ((i % 2) == 0)):
!       arr[ind] = i
!     else:
!       continue # do not use this value of i
&gt;     partitionHelp(arr, ind + 1, left - i, odd, even, order, notself)

&gt; def partition(args):
    # print (args)
&gt;   odd = args.odd
&gt;   even = args.even
&gt;   order = args.order
&gt;   val = args.value
&gt;   notself = args.notself
&gt;   if (odd and even):
!     sys.exit(&#39;-e and -o cannot be both set&#39;)
&gt;   if (even and (val % 2)):
!     sys.exit(&#39;-e cannot partition an odd number&#39;)
&gt;   print(&#39;== Partition &#39; + str(val) + &#39; ==&#39;)
&gt;   if (odd):
!     print(&#39;== Using only odd numbers ==&#39;)
&gt;   if (even):
!     print(&#39;== Using only even numbers ==&#39;)
&gt;   arr = [0] * val
&gt;   partitionHelp(arr, 0, val, odd, even, order, notself)

&gt; def checkArgs(args = None):
&gt;   parser = argparse.ArgumentParser(description=&#39;parse arguments&#39;)
&gt;   parser.add_argument(&#39;-o&#39;, &#39;--odd&#39;, action=&#39;store_true&#39;,
&gt;                       help = &#39;odd numbers only&#39;, default = False)
&gt;   parser.add_argument(&#39;-e&#39;, &#39;--even&#39;,action=&#39;store_true&#39;,
&gt;                       help = &#39;even numbers only&#39;, default = False)
&gt;   parser.add_argument(&#39;-r&#39;, &#39;--order&#39;,action=&#39;store_true&#39;,
&gt;                       help = &#39;orders do not matter&#39;, default = False)
&gt;   parser.add_argument(&#39;-s&#39;, &#39;--notself&#39;,action=&#39;store_true&#39;,
&gt;                       help = &#39;not to include itself&#39;, default = False)
&gt;   parser.add_argument(&#39;value&#39;, type = int,
&gt;                       help = &#39;number to parition&#39;)
&gt;   pargs = parser.parse_args(args)
&gt;   return pargs

&gt; if __name__== &quot;__main__&quot;:
&gt;   args = checkArgs(sys.argv[1:])
&gt;   partition(args)
</pre></div>
</div>
<p>Many lines change from ! (not tested) to &gt; (tested). The second test has
80% coverage, higher than the first test.</p>
<p>Figure <a class="reference external" href="#fig:compareconverage">[fig:comparecoverage]</a>.</p>
<div class="figure align-default">
<img alt="../_images/comparecoverage.png" src="../_images/comparecoverage.png" />
</div>
<p>Compare the two coverage outputs.</p>
<p>Here are the tests that can
achieve 100% coverage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">coverage</span> <span class="n">run</span> <span class="n">intpart</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">o</span> <span class="mi">5</span>
<span class="n">coverage</span> <span class="n">run</span> <span class="n">intpart</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">e</span> <span class="mi">6</span>
<span class="n">coverage</span> <span class="n">run</span> <span class="n">intpart</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">o</span> <span class="mi">8</span>
<span class="n">coverage</span> <span class="n">run</span> <span class="n">intpart</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">r</span> <span class="mi">5</span>
<span class="n">coverage</span> <span class="n">run</span> <span class="n">intpart</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">s</span> <span class="mi">4</span>
<span class="n">coverage</span> <span class="n">run</span> <span class="n">intpart</span><span class="o">.</span><span class="n">py</span>
<span class="n">coverage</span> <span class="n">run</span> <span class="n">intpart</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">h</span>
</pre></div>
</div>
<p>Is a higher coverage always better? This a common misunderstanding. The
purpose of testing is to discover problems. If a test can discover
problems, it is a good test even if it covers only a small percentage of
code. The next common misunderstanding may surprise you: Even if your
tests have 100% coverage, the program may still have undiscoverd
problems. “How can that be possible?” “100% test coverage.”</p>
<p>The misunderstanding occurs from the definition of coverage. Test
coverage is defined by whether each line has been tested; it is not
defined by whether each scenario has been tested. What is the
difference? Consider the following example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="p">(</span><span class="n">condition1</span><span class="p">):</span>
    <span class="c1"># A</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># B</span>
<span class="o">...</span>
<span class="k">if</span> <span class="p">(</span><span class="n">condition2</span><span class="p">):</span>
    <span class="c1"># C</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># D</span>
<span class="o">...</span>
</pre></div>
</div>
<p>The flow can be expressed in
Figure <a class="reference external" href="#fig:twoconditions">[fig:twoconditions]</a>.</p>
<img alt="../_images/twoconditions.png" src="../_images/twoconditions.png" />
<p>There are four possible scenarios of the two conditions:</p>
<ol class="arabic simple">
<li><p>condition1: True, condition2: True</p></li>
<li><p>condition1: True, condition2: False</p></li>
<li><p>condition1: False, condition2: True</p></li>
<li><p>condition1: False, condition2: False</p></li>
</ol>
<p>If a test has True for condition1 and False for condition2, then A and D
have been tested. Another test has False for condition1 and True for
condition2, then B and C have been tested. These two test cases have
tested A, B, C, and D. In other words, all code has been tested and the
coverage is 100%.</p>
<p>“Wait” “How can it be possible to get 100% coverage even with only two
tests? There are four scenarios.” You may ask.</p>
<p>That is the problem.</p>
<p>What does this mean? Does this mean coverage is not helpful? Test
coverage is very helpful. percentage. You should check whether the
specific lines you want to test have been covered. Do not focus on the
coverage number only.</p>
</div>
<div class="section" id="continous-integration">
<h2>Continous Integration<a class="headerlink" href="#continous-integration" title="Permalink to this headline">¶</a></h2>
<p>Have you ever had a situation when your software has a bug but it is
not discovered for a long time?  The existence of the bug and its
ability to escape detection may surprise your entire team. “How did
that happen?”, you may ask.  This may happen due to a wide variety of
reasons. One of the possible reasons is that the software has not been
well tested and as a result the bug is not detected. Testing is an
important method detecting bugs.  However, testing can be tideous.  It
is common that someone makes a “small” change and skips testing.
The person believes the change is so small and cannot possibly have
any bug.  If several people add a few small changes here and there,
the software soon is full of “small” bugs.  Why do people not test
their programs immediately after they have made changes?  One reason
is that testing require additional work.</p>
<p>Is it possible testing is fully automated without any additional
effort? <em>Continuous Integration</em> (CI) does exactly that.  You
still need to write testers. There is no way avoiding that part.  The
previous sections explain how to write tests.  What continuous
integration does is to automatically invole these testers whenver you
push your program to the shared repository.  This section uses
<code class="docutils literal notranslate"><span class="pre">Travis-CI</span></code> for continuous integration.</p>
<img alt="../_images/travis01.png" src="../_images/travis01.png" />
<p>Travis-CI.com is a website supporting continuous integration.</p>
<p>Using Travis-CI is quite simple. You need to add a special file whose
name is <code class="docutils literal notranslate"><span class="pre">.travis.yml</span></code>.  It tells Travis-CI what to do when changes
are pushed to github.  This is a simple example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ python3 --version
Python 3.5.2
</pre></div>
</div>
<p>The content of this file should be pretty easy to understand: It says
the repository uses Python as the language and version 3.5 is
required.  When changes are pushed, run <code class="docutils literal notranslate"><span class="pre">pytest</span></code> and it
automatically looks for a Python program starting with <code class="docutils literal notranslate"><span class="pre">test_</span></code> (such
as <code class="docutils literal notranslate"><span class="pre">test_intpart</span></code>}.  If it runn successfully, it is green.  If the
test fails, it will appear red.  You are encouraged to modify the
test, make it fail, and see what a failure looks like.</p>
<img alt="../_images/travis02.png" src="../_images/travis02.png" />
<p>Running pytest successfully in Travis-CI.</p>
</div>
<div class="section" id="limitations-of-testing">
<h2>Limitations of Testing<a class="headerlink" href="#limitations-of-testing" title="Permalink to this headline">¶</a></h2>
<p>It is important understanding that testing has limitations. It is
practically impossible testing every possible scenario. Every <code class="docutils literal notranslate"><span class="pre">if</span></code> is a
condition. A condition divides a program into two different paths
depending whether the condition is true or not. A non-trivial program
can easily have hundreds of conditions. As a simple explanation why it
is not possible testing every possible scenario. Let’s consider a
program with 100 independent conditions, i.e., whether one condition is true
or false does not affect any other condition. There are <span class="math notranslate nohighlight">\(2^{100}\)</span>
possible scenarios. The fastest computer in the world can perform
several hundred quadrillion (<span class="math notranslate nohighlight">\(10^{15}\)</span>) calculations per second;
this is a parallel computer but let’s not worry about that detail.
Because <span class="math notranslate nohighlight">\(\log_2(10) \approx 3.3\)</span>,
<span class="math notranslate nohighlight">\(10^{15} \approx 2 ^ {50}\)</span>. Thus, the fastest computer can check
as many as <span class="math notranslate nohighlight">\(2 ^ {50}\)</span> conditions per second. How many can this
computer check per minute? <span class="math notranslate nohighlight">\(2 ^ {50} \times 60\)</span>. How about a day
(86,400 seconds)? <span class="math notranslate nohighlight">\(2 ^ {50} \times 86400 \approx 2 ^ {66}\)</span>. In
order to test <span class="math notranslate nohighlight">\(2^{100}\)</span> possible scenarios, this computer needs to
work <span class="math notranslate nohighlight">\(2^{34}\)</span> days; this is very long time (much longer than the
history of humans). In fact, the situation is even worse. The estimation
above considers only two possible cases for each condition: true or
false. If the condition compares two numbers, then “every possible
scenario” means every possible pairs of these two numbers. What does
this mean? It would be completely impossible testing every possible
scenario of a program’s execution paths controlled by the conditions.</p>
<p>Does this mean there is no need to test because it is not possible
testing all possible scenarios? No. What it means is that testing has to
be done carefully so that testing can detect as many problems (i.e.,
bugs) as possible. Good tests should consider many different scenarios.</p>
</div>
<div class="section" id="halting-problems-unsolvable-problems">
<h2>Halting Problems: Unsolvable Problems<a class="headerlink" href="#halting-problems-unsolvable-problems" title="Permalink to this headline">¶</a></h2>
<p>Is it possible checking whether a program is correct by using another program?
More specifically, is it possible writing a program, called <span class="math notranslate nohighlight">\(p\)</span>, that has
three inputs: (1) another  program <span class="math notranslate nohighlight">\(q\)</span>, (2)  input data <span class="math notranslate nohighlight">\(i\)</span>,  and
(3) expected output <span class="math notranslate nohighlight">\(e\)</span> and decides whether program <span class="math notranslate nohighlight">\(q\)</span>
produces <span class="math notranslate nohighlight">\(e\)</span> when taking the input <span class="math notranslate nohighlight">\(i\)</span>, <em>without</em> running
the program <span class="math notranslate nohighlight">\(q\)</span>. This problem is at least as difficult as another problem:</p>
<p>Is it possible writing a program, called <span class="math notranslate nohighlight">\(p\)</span>, that has two
inputs: (1) another program <span class="math notranslate nohighlight">\(q\)</span>, (2) input data <span class="math notranslate nohighlight">\(i\)</span> and
decides whether program <span class="math notranslate nohighlight">\(q\)</span> will eventually stop or not (i.e.,
entering an infinite loop) when taking the input <span class="math notranslate nohighlight">\(i\)</span>.  This is
called thd <em>halting problem</em> in computation theory.  It turns that the
halting problem cannot be solved.</p>
<p>This is not a formal proof but it gives the intuition why the halting
problem cannot be solved.</p>
<p>First, it is possible to write a program <span class="math notranslate nohighlight">\(p\)</span> that takes another
program <span class="math notranslate nohighlight">\(q\)</span> as the input. An operating system is such as program
<span class="math notranslate nohighlight">\(p\)</span>. A compiler is also such a program <span class="math notranslate nohighlight">\(p\)</span>.  Second,
<span class="math notranslate nohighlight">\(p\)</span> cannot simply run <span class="math notranslate nohighlight">\(q\)</span> with input <span class="math notranslate nohighlight">\(i\)</span>. The reason
is that if <span class="math notranslate nohighlight">\(q\)</span> does not stop, <span class="math notranslate nohighlight">\(p\)</span> runs indefintely without
an answer.  We do not know whether <span class="math notranslate nohighlight">\(q\)</span> takes very long time and
will eventually stop, or it will never stop.  Third, since <span class="math notranslate nohighlight">\(p\)</span>
can take a program <span class="math notranslate nohighlight">\(q\)</span> as the input, <span class="math notranslate nohighlight">\(p\)</span> can also take
itself as the input.</p>
<p>So far, nothing is surprising. Next, we will explain why such a
program <span class="math notranslate nohighlight">\(p\)</span> is not possible. The “proof” uses contradition: We
first assume that it is possible creating such a program <span class="math notranslate nohighlight">\(p\)</span> and
then show that contradition occurs. Thus, the assumption (it is
possible creating such a program <span class="math notranslate nohighlight">\(p\)</span>) is wrong.</p>
<p>If it is possible creating <span class="math notranslate nohighlight">\(p\)</span>, then it is possible creating
<span class="math notranslate nohighlight">\(\tilde{p}\)</span> by changing <span class="math notranslate nohighlight">\(p\)</span> slightly:</p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(p\)</span>’s answer is yes, <span class="math notranslate nohighlight">\(\tilde{p}\)</span> enters an infinite loop and thus cannot answer the question.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(p\)</span>’s answer is no, <span class="math notranslate nohighlight">\(\tilde{p}\)</span> says yes.</p></li>
</ul>
<p>Next, rename <span class="math notranslate nohighlight">\(\tilde{p}\)</span> as <span class="math notranslate nohighlight">\(p\)</span>.</p>
<p>Now, there is a problem.  If <span class="math notranslate nohighlight">\(p\)</span>’s answer is Yes, it enters an
infinite loop and it will not halt.  If <span class="math notranslate nohighlight">\(p\)</span>’s answer is no, it
says yes.  In other words, <span class="math notranslate nohighlight">\(p\)</span>’s answer should be exactly the
opposite of its answer.  What does this mean? How can this be
possible?  Why do we get contradiction?</p>
<p>We get contradiction because we have made a wrong assumption: it is
possible creating <span class="math notranslate nohighlight">\(p\)</span>.  The truth is that it is not possible
creating a program <span class="math notranslate nohighlight">\(p\)</span> that takes a program <span class="math notranslate nohighlight">\(q\)</span> and an
input <span class="math notranslate nohighlight">\(i\)</span> and decides whether <span class="math notranslate nohighlight">\(q\)</span> halts when giving the
input <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>What does this mean to testing?  Deciding whether a program halts is
no more difficult deciding whether the program produces a correct
output.  If it impossible to solve the halting problem, it is
impossible writing a program <span class="math notranslate nohighlight">\(p\)</span> that decides whether program
<span class="math notranslate nohighlight">\(q\)</span> given input <span class="math notranslate nohighlight">\(i\)</span> produces expected output <span class="math notranslate nohighlight">\(e\)</span>.</p>
<p>Another unsolvable problem is determining whether two programs (that
are not identical) have the same outputs when given the same inputs.
Precisely, It is not possible creating a program <span class="math notranslate nohighlight">\(p\)</span> that takes
two inputs: (1) a program <span class="math notranslate nohighlight">\(q\)</span> and (2) the third program
<span class="math notranslate nohighlight">\(r\)</span> and answers whether <span class="math notranslate nohighlight">\(q\)</span> and <span class="math notranslate nohighlight">\(r\)</span> have the same
output for every possible input.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="chapter_ws.html" class="btn btn-neutral float-right" title="Web Services" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="chapter_cr.html" class="btn btn-neutral float-left" title="Code Review" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Yung-Hsiang Lu and George K. Thiruvathukal

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>