

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Hierarchical Clustering &mdash; Software Engineering for Machine Learning beta documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/theme_overrides.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Principal Component Analysis" href="chapter_pca.html" />
    <link rel="prev" title="K-Means Clustering" href="chapter_kmeans.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Software Engineering for Machine Learning
          

          
          </a>

          
            
            
              <div class="version">
                beta
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../frontmatter/preface.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/chapter_python.html">Introduction to Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/chapter_vc.html">Version Control</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/chapter_test.html">Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/chapter_ws.html">Web Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/chapter_ci.html">Continuous Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/chapter_graphics.html">Graphics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/chapter_reproducibility.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter_ml.html">Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter_kmeans.html">K-Means Clustering</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Hierarchical Clustering</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#limitations-of-the-k-mean-algorithm">Limitations of the k-mean Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="#examples-of-hierarchical-clustering">Examples of Hierarchical clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hierarchical-clustering-algorithm">Hierarchical Clustering Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="#define-distance-of-two-clusters">Define Distance of Two Clusters</a></li>
<li class="toctree-l2"><a class="reference internal" href="#implementation">Implementation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#data-structures">Data Structures</a></li>
<li class="toctree-l3"><a class="reference internal" href="#procedure">Procedure</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="chapter_pca.html">Principal Component Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter_practical.html">Practical Considerations of Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="chapter_floating_point.html">Floating Point and Finite Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised/chapter_supervised.html">Supervised Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised/chapter_gradient.html">Gradient Descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised/chapter_svm.html">Support Vector Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../supervised/chapter_neural_networks.html">Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../misc/chapter_building_the_book.html">Building the Book using Sphinx, GitHub Pages, and Travis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../misc/chapter_sphinx_demo.html">Sphinx Demonstration</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Software Engineering for Machine Learning</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Hierarchical Clustering</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/unsupervised/chapter_hierarchical.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="hierarchical-clustering">
<h1>Hierarchical Clustering<a class="headerlink" href="#hierarchical-clustering" title="Permalink to this headline">¶</a></h1>
<p>Learning Objectives</p>
<ul class="simple">
<li><p>Understand hierarchical clustering algorithm</p></li>
<li><p>Learn the binary tree and its properties</p></li>
<li><p>Use the tree’s properties to gain insight of data</p></li>
<li><p>Implement the algorithm for hierarchical clustering</p></li>
</ul>
<div class="section" id="limitations-of-the-k-mean-algorithm">
<h2>Limitations of the k-mean Algorithm<a class="headerlink" href="#limitations-of-the-k-mean-algorithm" title="Permalink to this headline">¶</a></h2>
<p>The previous chapter explains the k-mean clustering algorithm.  It is
simple and useful as an initial analysis of data but it also
has several major problems:</p>
<ul class="simple">
<li><p>There is no obvious reason to select a particular value of <cite>k</cite>.  The previous chapter shows an example: the data is generated for 10 clusters but the smallest distance occurs when <code class="docutils literal notranslate"><span class="pre">k</span></code> is 13.</p></li>
<li><p>The algorithm is non-deterministic and it is often necessary running the same program multiple times.</p></li>
<li><p>For a given cluster, there is no easy answer which other cluster is  closer.  It is possible to calculate the distances of centroids but  this requires additional work.</p></li>
<li><p>The k-mean algorithm assigns all data points to one of the <code class="docutils literal notranslate"><span class="pre">k</span></code>  clusters in the very first step.  Then the algorithm adjusts the  clusters by the finding closest centroid from each data  point. Because the initial assignments have direct impacts on the  final results, the program often needs to run multiple times for  selecting better results.</p></li>
</ul>
<p><em>Hierarchical Clustering</em> is a method that does  not have these same problems as the k-mean algorithm.</p>
</div>
<div class="section" id="examples-of-hierarchical-clustering">
<h2>Examples of Hierarchical clustering<a class="headerlink" href="#examples-of-hierarchical-clustering" title="Permalink to this headline">¶</a></h2>
<p>Hierarchical clustering iteratively finds the closest pair of clusters
(at the beginning, each data point is a cluster by itself).  The
algorithm makes the pair two children of a binary tree.  For
hierarchical clustering, it is called <em>dendrogram</em>, instead of binary
tree. This book uses both terms interchangably.  The tree node becomes
a new cluster.  The algorithm continues until only one tree node is
left.  Before formally describing the algorithm, let us go through
several examples.  The simplest case is when there is only one data
point but it is not very meaningful. Thus, let us start with two data
points.</p>
<table class="docutils align-center">
<colgroup>
<col style="width: 41%" />
<col style="width: 29%" />
<col style="width: 29%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>index</p></th>
<th class="head"><p>x</p></th>
<th class="head"><p>y</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>-66</p></td>
<td><p>45</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>95</p></td>
<td><p>-84</p></td>
</tr>
</tbody>
</table>
<p>They are the two children of a binary tree:</p>
<div class="figure align-center" id="id1">
<img alt="../_images/cluster2.png" src="../_images/cluster2.png" />
<p class="caption"><span class="caption-number">Figure 48 </span><span class="caption-text">Two data points are the two children of a binary tree.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<p>Next, we consider the case when there are four data points:</p>
<table class="docutils align-center">
<colgroup>
<col style="width: 41%" />
<col style="width: 29%" />
<col style="width: 29%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>index</p></th>
<th class="head"><p>x</p></th>
<th class="head"><p>y</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>-66</p></td>
<td><p>45</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>95</p></td>
<td><p>-84</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>-35</p></td>
<td><p>-70</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>26</p></td>
<td><p>94</p></td>
</tr>
</tbody>
</table>
<p>We use the <em>Euclidean distance</em> here. Consider two data points:
<span class="math notranslate nohighlight">\((x_a, y_a)\)</span> and <span class="math notranslate nohighlight">\((x_b, y_b)\)</span>. The distance between them
is defined as</p>
<p><span class="math notranslate nohighlight">\(\sqrt{(x_a - x_b)^2 + (y_a - y_b)^2}\)</span>.</p>
<p>Consider three data points: <span class="math notranslate nohighlight">\((x_a, y_a)\)</span>, <span class="math notranslate nohighlight">\((x_b, y_b)\)</span>,
and <span class="math notranslate nohighlight">\((x_c, y_c)\)</span>.  The following inequality is true.</p>
<p><span class="math notranslate nohighlight">\(\sqrt{(x_a - x_b)^2 + (y_a - y_b)^2} &gt; \sqrt{(x_a - x_c)^2 + (y_a - y_c)^2}  \Leftrightarrow ((x_a - x_b)^2 + (y_a - y_b)^2) &gt; ((x_a - x_c)^2 + (y_a - y_c)^2)\)</span>.</p>
<p>We care about only the order of the distance so we do not really care
about the square root.</p>
<p>The following table shows <span class="math notranslate nohighlight">\((x_a - x_b)^2 + (y_a - y_b)^2\)</span>
between the pairs of the data points.</p>
<table class="docutils align-center">
<colgroup>
<col style="width: 10%" />
<col style="width: 23%" />
<col style="width: 23%" />
<col style="width: 23%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>0</p></th>
<th class="head"><p>1</p></th>
<th class="head"><p>2</p></th>
<th class="head"><p>3</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>0</p></td>
<td><p>42562</p></td>
<td><p>14186</p></td>
<td><p>10865</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>42562</p></td>
<td><p>0</p></td>
<td><p>17096</p></td>
<td><p>36445</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>14186</p></td>
<td><p>17096</p></td>
<td><p>0</p></td>
<td><p>30617</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>10865</p></td>
<td><p>36445</p></td>
<td><p>30617</p></td>
<td><p>0</p></td>
</tr>
</tbody>
</table>
<p>The shortest distance (10865) occurs between <span class="math notranslate nohighlight">\((x_0, y_0)\)</span> and
<span class="math notranslate nohighlight">\((x_3,y_3)\)</span>.  They are the first pair to be put into the same
cluster.  Thus, points 0 and 3 are the two children of the same parent
node.</p>
<div class="figure align-center" id="id2">
<img alt="../_images/cluster4.png" src="../_images/cluster4.png" />
<p class="caption"><span class="caption-number">Figure 49 </span><span class="caption-text">Clusters of four data points. Do not worry about the colors, nor the numbers along the vertical axis. Pay attention to the shape only.</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</div>
<p>How do we represent the cluster that includes points 0 and 3?  There
are several different commonly used representations.  This example
uses the centroid method: a cluster is represented by the centroid of
the data points in the cluster.  The cluster that contains
<span class="math notranslate nohighlight">\((x_0, y_0)\)</span> and <span class="math notranslate nohighlight">\((x_3, y_3)\)</span> is represented by
<span class="math notranslate nohighlight">\((\frac{-66+26}{2}, \frac{45+94}{2}) = (-20, 69.5)\)</span>.  This
cluster is marked as the new <span class="math notranslate nohighlight">\((x_0, y_0)\)</span> and <span class="math notranslate nohighlight">\((x_3, y_3)\)</span>
no longer exists.  We can recompute the distances among the pairs of
points:</p>
<p>TO DO: make the table align right</p>
<table class="docutils align-center">
<colgroup>
<col style="width: 10%" />
<col style="width: 23%" />
<col style="width: 23%" />
<col style="width: 23%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>0</p></th>
<th class="head"><p>1</p></th>
<th class="head"><p>2</p></th>
<th class="head"><p>3</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>0</p></td>
<td><p>42562</p></td>
<td><p>14186</p></td>
<td><p>10865</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>42562</p></td>
<td><p>0</p></td>
<td><p>17096</p></td>
<td><p>36445</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>14186</p></td>
<td><p>17096</p></td>
<td><p>0</p></td>
<td><p>30617</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>10865</p></td>
<td><p>36445</p></td>
<td><p>30617</p></td>
<td><p>0</p></td>
</tr>
</tbody>
</table>
<p>The shortest distance (10865) occurs between <span class="math notranslate nohighlight">\((x_0, y_0)\)</span> and
<span class="math notranslate nohighlight">\((x_3,y_3)\)</span>.  They are the first pair to be put into the same
cluster.  Thus, points 0 and 3 are the two children of the same parent
node.</p>
<p>How do we represent the cluster that includes points 0 and 3?  There
are several different commonly used representations.  This example
uses the centroid method: a cluster is represented by the centroid of
the data points in the cluster.  The cluster that contains
<span class="math notranslate nohighlight">\((x_0, y_0)\)</span> and <span class="math notranslate nohighlight">\((x_3, y_3)\)</span> is represented by
<span class="math notranslate nohighlight">\((\frac{-66+26}{2}, \frac{45+94}{2}) = (-20, 69.5)\)</span>.  This
cluster is marked as the new <span class="math notranslate nohighlight">\((x_0, y_0)\)</span> and <span class="math notranslate nohighlight">\((x_3, y_3)\)</span>
no longer exists.  We can recompute the distances among the pairs of
points:</p>
<p>TO DO: make the table align right</p>
<table class="docutils align-center">
<colgroup>
<col style="width: 9%" />
<col style="width: 30%" />
<col style="width: 30%" />
<col style="width: 30%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>0</p></th>
<th class="head"><p>1</p></th>
<th class="head"><p>2</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>0.0</p></td>
<td><p>36787.25</p></td>
<td><p>19685.25</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>36787.25</p></td>
<td><p>0</p></td>
<td><p>17096</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>19685.25</p></td>
<td><p>17096</p></td>
<td><p>0</p></td>
</tr>
</tbody>
</table>
<p>Now, the shortest distance (17096) occurs between <span class="math notranslate nohighlight">\((x_1, y_1)\)</span>
and <span class="math notranslate nohighlight">\((x_2, y_2)\)</span>.  These two data points are the two children of
a tree node.  At this moment, there are only two clusters and they are
the children of a binary tree node.  The final result is shown below</p>
<div class="figure align-center" id="id3">
<img alt="../_images/cluster4.png" src="../_images/cluster4.png" />
<p class="caption"><span class="caption-number">Figure 50 </span><span class="caption-text">Clusters of four data points. Do not worry about the colors, nor the numbers along the vertical axis. Pay attention to the shape only.</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</div>
<p>Next, let’s add two more data points.</p>
<table class="docutils align-center">
<colgroup>
<col style="width: 41%" />
<col style="width: 29%" />
<col style="width: 29%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>index</p></th>
<th class="head"><p>x</p></th>
<th class="head"><p>y</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>-66</p></td>
<td><p>45</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>95</p></td>
<td><p>-84</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>-35</p></td>
<td><p>-70</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>26</p></td>
<td><p>94</p></td>
</tr>
<tr class="row-even"><td><p>4</p></td>
<td><p>15</p></td>
<td><p>20</p></td>
</tr>
<tr class="row-odd"><td><p>5</p></td>
<td><p>66</p></td>
<td><p>-3</p></td>
</tr>
</tbody>
</table>
<p>The pair-wise distances is shown below</p>
<table class="docutils align-center">
<colgroup>
<col style="width: 7%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>0</p></th>
<th class="head"><p>1</p></th>
<th class="head"><p>2</p></th>
<th class="head"><p>3</p></th>
<th class="head"><p>4</p></th>
<th class="head"><p>5</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>0</p></td>
<td><p>42562</p></td>
<td><p>14186</p></td>
<td><p>10865</p></td>
<td><p>7186</p></td>
<td><p>19728</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>42562</p></td>
<td><p>0</p></td>
<td><p>17096</p></td>
<td><p>36445</p></td>
<td><p>17216</p></td>
<td><p>7402</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>14186</p></td>
<td><p>17096</p></td>
<td><p>0</p></td>
<td><p>30617</p></td>
<td><p>10600</p></td>
<td><p>14690</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>10865</p></td>
<td><p>36445</p></td>
<td><p>30617</p></td>
<td><p>0</p></td>
<td><p>5597</p></td>
<td><p>11009</p></td>
</tr>
<tr class="row-even"><td><p>4</p></td>
<td><p>7186</p></td>
<td><p>17216</p></td>
<td><p>10600</p></td>
<td><p>5597</p></td>
<td><p>0</p></td>
<td><p>3130</p></td>
</tr>
<tr class="row-odd"><td><p>5</p></td>
<td><p>19728</p></td>
<td><p>7402</p></td>
<td><p>14690</p></td>
<td><p>11009</p></td>
<td><p>3130</p></td>
<td><p>0</p></td>
</tr>
</tbody>
</table>
<p>The shortest distance (3130) occurs between <span class="math notranslate nohighlight">\((x_4, y_4)\)</span> and
<span class="math notranslate nohighlight">\((x_5, y_5)\)</span>.  These two data points are the two children of a
node.  This cluster is represented by the centroid <span class="math notranslate nohighlight">\((\frac{15 +
66}{2}, \frac{20 + (-3)}{2}) = (\frac{81}{2}, \frac{17}{2}) = (40.5,
8.5)\)</span>.  The cluster is expressed as <span class="math notranslate nohighlight">\((x_4, y_4)\)</span> and
<span class="math notranslate nohighlight">\((x_5, y_5)\)</span> is removed.  Now there are four data points and one
cluster.  The distances are shown in the following table:</p>
<table class="docutils align-center">
<colgroup>
<col style="width: 6%" />
<col style="width: 19%" />
<col style="width: 19%" />
<col style="width: 19%" />
<col style="width: 17%" />
<col style="width: 19%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>0</p></th>
<th class="head"><p>1</p></th>
<th class="head"><p>2</p></th>
<th class="head"><p>3</p></th>
<th class="head"><p>4</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>0</p></td>
<td><p>42562</p></td>
<td><p>14186</p></td>
<td><p>10865</p></td>
<td><p>12674.5</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>42562</p></td>
<td><p>0</p></td>
<td><p>17096</p></td>
<td><p>36445</p></td>
<td><p>11526.5</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>14186</p></td>
<td><p>17096</p></td>
<td><p>0</p></td>
<td><p>30617</p></td>
<td><p>11862.5</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>10865</p></td>
<td><p>36445</p></td>
<td><p>30617</p></td>
<td><p>0</p></td>
<td><p>7520.5</p></td>
</tr>
<tr class="row-even"><td><p>4</p></td>
<td><p>12674.5</p></td>
<td><p>11526.5</p></td>
<td><p>11862.5</p></td>
<td><p>7520.5</p></td>
<td><p>0</p></td>
</tr>
</tbody>
</table>
<p>The smallest distance is 7520.5 and it is between <span class="math notranslate nohighlight">\((x_3, y_3)\)</span>
and the cluster created earlier. Thus, <span class="math notranslate nohighlight">\((x_3, y_3)\)</span> and the
cluster are put together by making them the two childrens of a binary
tree node.  This process continues until there is only cluster left.
The final binary tree is shown below:</p>
<div class="figure align-center" id="id4">
<img alt="../_images/cluster6.png" src="../_images/cluster6.png" />
<p class="caption"><span class="caption-number">Figure 51 </span><span class="caption-text">Cluster of the six data points.</span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</div>
<p>The examples are generated using the following program:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/python3</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">dendrogram</span><span class="p">,</span> <span class="n">linkage</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">pdist</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">distance</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y2</span><span class="p">):</span>
    <span class="c1"># no need to take square root</span>
    <span class="c1"># print (x1 - x2, y1 - y2)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x1</span> <span class="o">-</span> <span class="n">x2</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x1</span> <span class="o">-</span> <span class="n">x2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">y1</span> <span class="o">-</span> <span class="n">y2</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y1</span> <span class="o">-</span> <span class="n">y2</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">numdp</span> <span class="o">=</span> <span class="mi">6</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numdp</span><span class="p">):</span>
        <span class="n">x</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
                  <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)])</span>
    <span class="k">print</span> <span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;centroid&#39;</span><span class="p">)</span>
    <span class="n">dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="n">pairdist</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i1</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numdp</span><span class="p">):</span>
        <span class="n">row</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">numdp</span>
        <span class="n">pairdist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i1</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numdp</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i2</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numdp</span><span class="p">):</span>
            <span class="n">d</span> <span class="o">=</span> <span class="n">distance</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">i1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">i2</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">i2</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">pairdist</span><span class="p">[</span><span class="n">i1</span><span class="p">][</span><span class="n">i2</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span>
        <span class="k">print</span> <span class="p">(</span><span class="s1">&#39;pairdist&#39;</span><span class="p">,</span> <span class="n">pairdist</span><span class="p">[</span><span class="n">i1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="section" id="hierarchical-clustering-algorithm">
<h2>Hierarchical Clustering Algorithm<a class="headerlink" href="#hierarchical-clustering-algorithm" title="Permalink to this headline">¶</a></h2>
<p>The hierarchical clustering algorithm starts by treating each data
point as a cluster. Then it repetively finds the closest two clusters.
These two clusters are the two children of a binary tree node and form
one cluster.  As a result, two clusters become one cluster.  This
process continues until only one cluster is left.  The algorithm is
described below:</p>
<div class="figure align-center" id="id5">
<img alt="../_images/hierarchicalalgorithm.png" src="../_images/hierarchicalalgorithm.png" />
<p class="caption"><span class="caption-number">Figure 52 </span><span class="caption-text">Hierarchical Clustering Algorithm</span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="define-distance-of-two-clusters">
<h2>Define Distance of Two Clusters<a class="headerlink" href="#define-distance-of-two-clusters" title="Permalink to this headline">¶</a></h2>
<p>The earlier examples use the centroid to express each cluster.  Other
definitions of clusters’ distances are also used.  There are four
commonly adopted definitions for the distance of two clusters (<code class="docutils literal notranslate"><span class="pre">An</span>
<span class="pre">Introduction</span> <span class="pre">to</span> <span class="pre">Statistical</span> <span class="pre">Learning</span> <span class="pre">by</span> <span class="pre">James,</span> <span class="pre">Witten,</span> <span class="pre">Hastie,</span> <span class="pre">and</span>
<span class="pre">Tibshirani</span></code>): <em>complete</em>, <em>single</em>, <em>average</em>, and <em>centroid</em>.  They
are described below.</p>
<p>Suppose <span class="math notranslate nohighlight">\(A = \{a_1, a_2, ..., a_n\}\)</span> is a cluster and <span class="math notranslate nohighlight">\(a_1\)</span>,
<span class="math notranslate nohighlight">\(a_2\)</span>, …, <span class="math notranslate nohighlight">\(a_n\)</span> are the <span class="math notranslate nohighlight">\(n\)</span> data points in this
cluster.  Suppose <span class="math notranslate nohighlight">\(B = \{b_1, b_2, ..., b_m\}\)</span> is another cluster
and <span class="math notranslate nohighlight">\(b_1\)</span>, <span class="math notranslate nohighlight">\(b_2\)</span>, …, <span class="math notranslate nohighlight">\(b_m\)</span> are the <span class="math notranslate nohighlight">\(m\)</span> data
points in this cluster.  The distance between these two clusters can
be defined as</p>
<ul class="simple">
<li><p>Complete: Compute the pairwise distances of every point in  <span class="math notranslate nohighlight">\(A\)</span> and every point in <span class="math notranslate nohighlight">\(B\)</span>, then select the  largest distance.  Mathematically, the distance is defined as <span class="math notranslate nohighlight">\(\underset{a_i \in A, b_j \in B}{\max}{|a_i - b_j|}\)</span>.   Here, <span class="math notranslate nohighlight">\(|a_i - b_j|\)</span> means the distance of the two points.</p></li>
<li><p>Single. This definition considers the smallest distance  among all pairs of points in <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>:  <span class="math notranslate nohighlight">\(\underset{a_i \in A, b_j \in B}{\min}{|a_i - b_j|}\)</span>.</p></li>
<li><p>Average. This definition computes the average of the pairwise  distances: <span class="math notranslate nohighlight">\(\frac{1}{n \times m} \underset{a_i \in A, b_j \in B}{\Sigma} {|a_i - b_j|}\)</span>.</p></li>
<li><p>Centroid. Find the centroid <span class="math notranslate nohighlight">\(c_A\)</span> of <span class="math notranslate nohighlight">\(A\)</span> and the    centroid of <span class="math notranslate nohighlight">\(c_B\)</span> of <span class="math notranslate nohighlight">\(B\)</span> using in Chapter of k-mean.   The distance of the two clusters is the distance of the two    centroids: <span class="math notranslate nohighlight">\(| c_A - c_B|\)</span>.</p></li>
</ul>
</div>
<div class="section" id="implementation">
<h2>Implementation<a class="headerlink" href="#implementation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="data-structures">
<h3>Data Structures<a class="headerlink" href="#data-structures" title="Permalink to this headline">¶</a></h3>
<p>TO DO: Explain list and tree</p>
</div>
<div class="section" id="procedure">
<h3>Procedure<a class="headerlink" href="#procedure" title="Permalink to this headline">¶</a></h3>
<p>To implement hierarchical clustering, we will use two types of data
structures: <em>binary tree node</em> and <em>list node</em>.  Each binary tree node
represents a cluster. The original data points are stored in the
<em>leaf</em> nodes and each data point is a cluster of its own. These binary
tree nodes are stored in a list.  In a binary tree, a node is a leaf
if it has no child.  Then, the cloest two clusters are fused together
into a single cluster.  The two clusters are removed from the list and
the new cluster is added to the list.  In each step, two clusters are
removed and one cluster is added.  As a result, the number of clusters
is reduced by one in each step.  This process continues until only one
cluster is left.</p>
<p>TO DO: Make a figure</p>
<p>The program’s starting point is relatively simple.  It accepts one
argument as the input file. Please notice that it is different from
the k-mean solution since hierarchical clustering does not need the
value of <code class="docutils literal notranslate"><span class="pre">k</span></code>.</p>
<p>TO DO: Explain the code</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="ch">#! /usr/bin/python</span>
<span class="c1"># main.py for hierarchical clustering</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">cluster</span>
<span class="kn">import</span> <span class="nn">argparse</span>

<span class="k">def</span> <span class="nf">checkArgs</span><span class="p">(</span><span class="n">argv</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">&#39;parse arguments&#39;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;-f&#39;</span><span class="p">,</span> <span class="s1">&#39;--filename&#39;</span><span class="p">,</span> 
                        <span class="n">help</span> <span class="o">=</span> <span class="s1">&#39;name of the data file&#39;</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="s1">&#39;data.txt&#39;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;-d&#39;</span><span class="p">,</span> <span class="s1">&#39;--distance&#39;</span><span class="p">,</span> 
                        <span class="n">help</span> <span class="o">=</span> <span class="s1">&#39;distance definition&#39;</span><span class="p">,</span>
                        <span class="n">choices</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;t&#39;</span><span class="p">))</span>
    <span class="c1"># four methods to measure distances between clusters:</span>
    <span class="c1"># complete, single, average, centroid</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">(</span><span class="n">argv</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">args</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">checkArgs</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="n">cluster</span><span class="o">.</span><span class="n">cluster</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># cluster.py for hierarchical clustering</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">hclist</span> <span class="kn">import</span> <span class="n">HCList</span>

<span class="k">def</span> <span class="nf">cluster</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">filename</span>
    <span class="n">distdef</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">distance</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">fhd</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="c1"># file handler</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="s1">&#39;open fail&#39;</span><span class="p">)</span>
    <span class="c1"># create an empty hierarchical clustering list</span>
    <span class="n">hcl</span> <span class="o">=</span> <span class="n">HCList</span><span class="p">(</span><span class="n">distdef</span><span class="p">)</span>
    <span class="c1"># read the data</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">oneline</span> <span class="ow">in</span> <span class="n">fhd</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">oneline</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
        <span class="n">count</span> <span class="o">=</span> <span class="n">count</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="c1"># print &quot;add to list&quot;, data</span>
        <span class="n">hcl</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="c1"># print &quot;--- finish reading file ---&quot;    </span>
    <span class="n">hcl</span><span class="o">.</span><span class="n">printList</span><span class="p">()</span>
    <span class="n">hcl</span><span class="o">.</span><span class="n">cluster</span><span class="p">()</span>
    <span class="k">print</span> <span class="s2">&quot;--- final cluster ---&quot;</span>    
    <span class="n">hcl</span><span class="o">.</span><span class="n">printList</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># hctree.py for hierarchical</span>
<span class="k">class</span> <span class="nc">TreeNode</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">val</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">left</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">right</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">printNode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span> <span class="o">==</span> <span class="bp">None</span><span class="p">):</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">left</span> <span class="o">==</span> <span class="bp">None</span><span class="p">)</span> <span class="ow">and</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">right</span> <span class="o">==</span> <span class="bp">None</span><span class="p">)):</span>
            <span class="k">print</span> <span class="s2">&quot;Leaf: &quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span> <span class="bp">self</span><span class="o">.</span><span class="n">value</span>

        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">left</span> <span class="o">!=</span> <span class="bp">None</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">left</span><span class="o">.</span><span class="n">printNode</span><span class="p">()</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">right</span> <span class="o">!=</span> <span class="bp">None</span><span class="p">):</span>           
            <span class="bp">self</span><span class="o">.</span><span class="n">right</span><span class="o">.</span><span class="n">printNode</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">getLeft</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">left</span>

    <span class="k">def</span> <span class="nf">getRight</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">right</span>

    <span class="k">def</span> <span class="nf">distanceComplete</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trnd</span><span class="p">):</span>
        <span class="n">dist1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distanceCompleteNode</span><span class="p">(</span><span class="n">trnd</span><span class="p">)</span>
        <span class="n">dist2</span> <span class="o">=</span> <span class="n">dist1</span>
        <span class="n">dist3</span> <span class="o">=</span> <span class="n">dist1</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">left</span> <span class="o">!=</span> <span class="bp">None</span><span class="p">):</span>
            <span class="n">dist2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distanceCompleteNode</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">left</span><span class="p">,</span> <span class="n">trnd</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">right</span> <span class="o">!=</span> <span class="bp">None</span><span class="p">):</span>
            <span class="n">dist3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distanceCompleteNode</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">right</span><span class="p">,</span> <span class="n">trnd</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">dist1</span><span class="p">,</span> <span class="n">dist2</span><span class="p">,</span> <span class="n">dist3</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">distanceSingle</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trnd</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">distanceAverage</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trnd</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">distanceCentroid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trnd</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">0</span>
    
    <span class="k">def</span> <span class="nf">_distance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sndnode</span><span class="p">):</span>
        <span class="nb">sum</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">)):</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">-</span> <span class="n">sndnode</span><span class="o">.</span><span class="n">value</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
            <span class="nb">sum</span> <span class="o">=</span> <span class="n">dist</span> <span class="o">*</span> <span class="n">dist</span>
        <span class="k">return</span> <span class="nb">sum</span>
    
    <span class="k">def</span> <span class="nf">_distanceCompleteNode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trnd</span><span class="p">):</span>
        <span class="c1"># find the maximum distance of one node with all nodes in trnd</span>
        <span class="n">dist1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distance</span><span class="p">(</span><span class="n">trnd</span><span class="p">)</span>
        <span class="n">dist2</span> <span class="o">=</span> <span class="n">dist1</span>
        <span class="n">dist3</span> <span class="o">=</span> <span class="n">dist1</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">trnd</span><span class="o">.</span><span class="n">left</span> <span class="o">!=</span> <span class="bp">None</span><span class="p">):</span>
            <span class="n">dist2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distanceCompleteNode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trnd</span><span class="o">.</span><span class="n">left</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">trnd</span><span class="o">.</span><span class="n">right</span> <span class="o">!=</span> <span class="bp">None</span><span class="p">):</span>
            <span class="n">dist3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_distanceCompleteNode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trnd</span><span class="o">.</span><span class="n">right</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">dist1</span><span class="p">,</span> <span class="n">dist2</span><span class="p">,</span> <span class="n">dist3</span><span class="p">)</span>
    
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">hctree</span> <span class="kn">import</span> <span class="n">TreeNode</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="k">class</span> <span class="nc">ListNode</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tn</span><span class="p">):</span>
        <span class="c1"># double linked list, with after and before</span>
        <span class="c1"># use after and before, not next and prev</span>
        <span class="c1"># because next is already defined in Python</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trnode</span> <span class="o">=</span> <span class="n">tn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">after</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">before</span> <span class="o">=</span> <span class="bp">None</span>
    
<span class="k">class</span> <span class="nc">HCList</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">distdef</span><span class="p">):</span>
        <span class="c1"># the list has a dummy node. It is both head and tail</span>
        <span class="n">trnd</span> <span class="o">=</span> <span class="n">TreeNode</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
        <span class="n">lsnd</span> <span class="o">=</span> <span class="n">ListNode</span><span class="p">(</span><span class="n">trnd</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">lsnd</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">tail</span> <span class="o">=</span> <span class="n">lsnd</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist</span> <span class="o">=</span> <span class="n">distdef</span> <span class="c1"># definition of distance</span>

    <span class="c1"># add a cluster to the list</span>
    <span class="c1"># a new cluster is stored in a tree node</span>
    <span class="c1"># the tree node is added to the list</span>
    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
        <span class="n">trnd</span> <span class="o">=</span> <span class="n">TreeNode</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
        <span class="n">lsnd</span> <span class="o">=</span> <span class="n">ListNode</span><span class="p">(</span><span class="n">trnd</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tail</span><span class="o">.</span><span class="n">after</span> <span class="o">=</span> <span class="n">lsnd</span>
        <span class="n">lsnd</span><span class="o">.</span><span class="n">before</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tail</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tail</span> <span class="o">=</span> <span class="n">lsnd</span>
        <span class="k">return</span> <span class="n">trnd</span>

    <span class="k">def</span> <span class="nf">delete</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lsnd</span><span class="p">):</span>
        <span class="c1"># cannot delete the first node (dummy)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">lsnd</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="p">):</span>
            <span class="k">print</span> <span class="s2">&quot;ERROR, delete dummy head&quot;</span>
            <span class="k">return</span>
        <span class="c1"># delete the last node</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">lsnd</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">tail</span><span class="p">):</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">tail</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tail</span><span class="o">.</span><span class="n">before</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tail</span><span class="o">.</span><span class="n">after</span> <span class="o">=</span> <span class="bp">None</span>
            <span class="k">return</span>
        <span class="c1"># delete a node in the middle </span>
        <span class="n">before</span> <span class="o">=</span> <span class="n">lsnd</span><span class="o">.</span><span class="n">before</span>
        <span class="n">after</span>  <span class="o">=</span> <span class="n">lsnd</span><span class="o">.</span><span class="n">after</span>
        <span class="n">before</span><span class="o">.</span><span class="n">after</span> <span class="o">=</span> <span class="n">after</span>
        <span class="n">after</span><span class="o">.</span><span class="n">before</span> <span class="o">=</span> <span class="n">before</span>

    <span class="k">def</span> <span class="nf">printList</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">print</span> <span class="s2">&quot;HCList::printList&quot;</span>
        <span class="n">lsnd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="o">.</span><span class="n">after</span>
        <span class="k">while</span> <span class="p">(</span><span class="n">lsnd</span> <span class="o">!=</span> <span class="bp">None</span><span class="p">):</span>
            <span class="n">lsnd</span><span class="o">.</span><span class="n">trnode</span><span class="o">.</span><span class="n">printNode</span><span class="p">()</span>
            <span class="n">lsnd</span> <span class="o">=</span> <span class="n">lsnd</span><span class="o">.</span><span class="n">after</span>

    <span class="k">def</span> <span class="nf">distance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lsnd1</span><span class="p">,</span> <span class="n">lsnd2</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">dist</span> <span class="o">==</span> <span class="s1">&#39;c&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dist</span> <span class="o">==</span> <span class="s1">&#39;C&#39;</span><span class="p">)):</span>
            <span class="k">return</span> <span class="n">lsnd1</span><span class="o">.</span><span class="n">distanceComplete</span><span class="p">(</span><span class="n">lsnd2</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">dist</span> <span class="o">==</span> <span class="s1">&#39;s&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dist</span> <span class="o">==</span> <span class="s1">&#39;S&#39;</span><span class="p">)):</span>
            <span class="k">return</span> <span class="n">lsnd1</span><span class="o">.</span><span class="n">distanceSimple</span><span class="p">(</span><span class="n">lsnd2</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">dist</span> <span class="o">==</span> <span class="s1">&#39;a&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dist</span> <span class="o">==</span> <span class="s1">&#39;A&#39;</span><span class="p">)):</span>
            <span class="k">return</span> <span class="n">lsnd1</span><span class="o">.</span><span class="n">distanceAverage</span><span class="p">(</span><span class="n">lsnd2</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">dist</span> <span class="o">==</span> <span class="s1">&#39;t&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dist</span> <span class="o">==</span> <span class="s1">&#39;T&#39;</span><span class="p">)):</span>
            <span class="k">return</span> <span class="n">lsnd1</span><span class="o">.</span><span class="n">distanceCentroid</span><span class="p">(</span><span class="n">lsnd2</span><span class="p">)</span>
        <span class="k">print</span> <span class="p">(</span><span class="s1">&#39;Unknown method for calcuating distance&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">merge</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trnd1</span><span class="p">,</span> <span class="n">trnd2</span><span class="p">):</span>
        <span class="c1"># value not used for non-leaf nodes</span>
        <span class="n">val</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">trnd1</span><span class="o">.</span><span class="n">value</span><span class="p">)</span> 
        <span class="n">trnd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="p">(</span><span class="n">val</span><span class="p">)</span>
        <span class="n">trnd</span><span class="o">.</span><span class="n">left</span> <span class="o">=</span> <span class="n">trnd1</span>
        <span class="n">trnd</span><span class="o">.</span><span class="n">right</span> <span class="o">=</span> <span class="n">trnd2</span>
        <span class="n">trnd</span><span class="o">.</span><span class="n">printNode</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">cluster</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># this implementation is not efficient but it should</span>
        <span class="c1"># be easy to understand</span>
        <span class="c1"># remember that head is the dummy node</span>
        <span class="k">while</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="o">.</span><span class="n">after</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tail</span><span class="p">):</span>
            <span class="c1"># at least two list nodes, not done yet</span>
            <span class="c1"># distance of the first two list nodes as reference</span>
            <span class="n">lsnd1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="o">.</span><span class="n">after</span>
            <span class="n">lsnd2</span> <span class="o">=</span> <span class="n">lsnd1</span><span class="o">.</span><span class="n">after</span>
            <span class="n">mindist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="n">lsnd1</span><span class="p">,</span> <span class="n">lsnd2</span><span class="p">)</span>

            <span class="c1"># find the pair of the smallest distance</span>
            <span class="n">flsnd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="o">.</span><span class="n">after</span> <span class="c1"># first list node</span>
            <span class="k">while</span> <span class="p">(</span><span class="n">flsnd</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tail</span><span class="p">):</span>
                <span class="n">slsnd</span> <span class="o">=</span> <span class="n">flsnd</span><span class="o">.</span><span class="n">after</span> <span class="c1"># second list node</span>
                <span class="k">while</span> <span class="p">(</span><span class="n">slsnd</span> <span class="o">!=</span> <span class="bp">None</span><span class="p">):</span>
                    <span class="n">dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="n">flsnd</span><span class="p">,</span> <span class="n">slsnd</span><span class="p">)</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">dist</span> <span class="o">&lt;</span> <span class="n">mindist</span><span class="p">):</span> <span class="c1"># notice, no =</span>
                        <span class="n">dist</span> <span class="o">=</span> <span class="n">mindist</span>
                        <span class="n">lsnd1</span> <span class="o">=</span> <span class="n">flsnd</span>
                        <span class="n">lsnd2</span> <span class="o">=</span> <span class="n">slsnd</span>
                    <span class="n">slsnd</span> <span class="o">=</span> <span class="n">slsnd</span><span class="o">.</span><span class="n">after</span>
                <span class="n">flsnd</span> <span class="o">=</span> <span class="n">flsnd</span><span class="o">.</span><span class="n">after</span>                        
            <span class="c1"># remove the two nodes that have the smallest distance</span>
            <span class="c1"># from the list</span>
            <span class="k">print</span> <span class="s2">&quot;merge&quot;</span><span class="p">,</span> <span class="n">lsnd1</span><span class="o">.</span><span class="n">trnode</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">lsnd2</span><span class="o">.</span><span class="n">trnode</span><span class="o">.</span><span class="n">value</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">lsnd1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">lsnd2</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">lsnd1</span><span class="o">.</span><span class="n">trnode</span><span class="p">,</span> <span class="n">lsnd2</span><span class="o">.</span><span class="n">trnode</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="o">.</span><span class="n">after</span><span class="o">.</span><span class="n">trnode</span>
            
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="chapter_pca.html" class="btn btn-neutral float-right" title="Principal Component Analysis" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="chapter_kmeans.html" class="btn btn-neutral float-left" title="K-Means Clustering" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Yung-Hsiang Lu and George K. Thiruvathukal

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>